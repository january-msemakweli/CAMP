{"version":3,"sources":["../package.json","../src/server.ts","../src/logs.ts","../src/pg-meta/columns.sql","../src/pg-meta/extensions.sql","../src/pg-meta/tables.sql","../src/pg-meta/index.ts","../src/pricing.ts","../src/util.ts"],"names":["version","getLogQuery","service","limit","stripIndent","schemas"],"mappings":"AAEE,04BAAAA,CAAAA,CAAW,OAAA,CCFb,+CAAsC,0BACpB,yCCDU,SAEZC,CAAAA,CACdC,CAAAA,CAQAC,CAAAA,CAAgB,GAAA,CAChB,CACA,MAAA,CAAQD,CAAAA,CAAS,CACf,IAAK,KAAA,CACH,OAAOE,uBAAAA,CAAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAAA,EAOGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,IAAK,eAAA,CACH,OAAOC,uBAAAA,CAAAA;AAAA;AAAA;AAAA,cAAA,EAGGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,IAAK,UAAA,CACH,OAAOC,uBAAAA,CAAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAAA,EAKGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,IAAK,eAAA,CACH,OAAOC,uBAAAA,CAAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAAA,EAMGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,IAAK,MAAA,CACH,OAAOC,uBAAAA,CAAAA;AAAA;AAAA;AAAA;AAAA,cAAA,EAIGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,IAAK,SAAA,CACH,OAAOC,uBAAAA,CAAAA;AAAA;AAAA;AAAA,cAAA,EAGGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,IAAK,UAAA,CACH,OAAOC,uBAAAA,CAAAA;AAAA;AAAA;AAAA,cAAA,EAGGD,CAAK,CAAA;AAAA,MAAA,CAAA,CAEjB,OAAA,CACE,MAAM,IAAI,KAAA,CAAM,CAAA,8BAAA,EAAiCD,CAAO,CAAA,CAAA;ACnE9D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACc8BG;AAClB;AAEgB,iBAAA;AACE,kBAAA;AAAA;AAAA;AAGwC,MAAA;AAAA;AAKR,EAAA;AAmBrD;AAAA;AAAA;AAIyD,gCAAA;AAAA;AAEhD,UAAA;AAAA;AAAA;AAGD,SAAA;ACxBb,EAAA;ACO2C","file":"/Users/grichardson/Documents/dev/supabase/mcp-server-supabase/packages/mcp-server-supabase/dist/chunk-LWHIOKZY.cjs","sourcesContent":["{\n  \"name\": \"@supabase/mcp-server-supabase\",\n  \"version\": \"0.3.5\",\n  \"description\": \"MCP server for interacting with Supabase\",\n  \"license\": \"Apache-2.0\",\n  \"type\": \"module\",\n  \"main\": \"dist/index.cjs\",\n  \"types\": \"dist/index.d.ts\",\n  \"sideEffects\": false,\n  \"scripts\": {\n    \"build\": \"tsup --clean\",\n    \"prepublishOnly\": \"npm run build\",\n    \"test\": \"vitest\",\n    \"test:e2e\": \"vitest --project e2e\",\n    \"test:unit\": \"vitest --project unit\",\n    \"generate:management-api-types\": \"openapi-typescript https://api.supabase.com/api/v1-json -o ./src/management-api/types.ts\"\n  },\n  \"files\": [\n    \"dist/**/*\"\n  ],\n  \"bin\": {\n    \"mcp-server-supabase\": \"./dist/stdio.js\"\n  },\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\",\n      \"default\": \"./dist/index.cjs\"\n    }\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.4.1\",\n    \"@supabase/mcp-utils\": \"0.1.3\",\n    \"common-tags\": \"^1.8.2\",\n    \"openapi-fetch\": \"^0.13.4\",\n    \"zod\": \"^3.24.1\"\n  },\n  \"devDependencies\": {\n    \"@ai-sdk/anthropic\": \"^1.2.9\",\n    \"@electric-sql/pglite\": \"^0.2.17\",\n    \"@total-typescript/tsconfig\": \"^1.0.4\",\n    \"@types/common-tags\": \"^1.8.4\",\n    \"@types/node\": \"^22.8.6\",\n    \"ai\": \"^4.3.4\",\n    \"date-fns\": \"^4.1.0\",\n    \"dotenv\": \"^16.5.0\",\n    \"msw\": \"^2.7.3\",\n    \"nanoid\": \"^5.1.5\",\n    \"openapi-typescript\": \"^7.5.0\",\n    \"openapi-typescript-helpers\": \"^0.0.15\",\n    \"prettier\": \"^3.3.3\",\n    \"tsup\": \"^8.3.5\",\n    \"tsx\": \"^4.19.2\",\n    \"typescript\": \"^5.6.3\",\n    \"vitest\": \"^2.1.9\"\n  }\n}\n","import { createMcpServer, tool } from '@supabase/mcp-utils';\nimport { z } from 'zod';\nimport { version } from '../package.json';\nimport { getLogQuery } from './logs.js';\nimport {\n  assertSuccess,\n  createManagementApiClient,\n  type ManagementApiClient,\n} from './management-api/index.js';\nimport { generatePassword } from './password.js';\nimport { listExtensionsSql, listTablesSql } from './pg-meta/index.js';\nimport type { PostgresExtension, PostgresTable } from './pg-meta/types.js';\nimport { getBranchCost, getNextProjectCost, type Cost } from './pricing.js';\nimport {\n  AWS_REGION_CODES,\n  getClosestAwsRegion,\n  getCountryCode,\n  getCountryCoordinates,\n} from './regions.js';\nimport { hashObject } from './util.js';\n\nexport type SupabasePlatformOptions = {\n  /**\n   * The access token for the Supabase Management API.\n   */\n  accessToken: string;\n\n  /**\n   * The API URL for the Supabase Management API.\n   */\n  apiUrl?: string;\n};\n\nexport type SupabaseMcpServerOptions = {\n  /**\n   * Platform options for Supabase.\n   */\n  platform: SupabasePlatformOptions;\n\n  /**\n   * Executes database queries in read-only mode if true.\n   */\n  readOnly?: boolean;\n};\n\n/**\n * Creates an MCP server for interacting with Supabase.\n */\nexport function createSupabaseMcpServer(options: SupabaseMcpServerOptions) {\n  const managementApiUrl =\n    options.platform.apiUrl ?? 'https://api.supabase.com';\n\n  let managementApiClient: ManagementApiClient;\n\n  async function executeSql<T>(projectId: string, query: string): Promise<T[]> {\n    const response = await managementApiClient.POST(\n      '/v1/projects/{ref}/database/query',\n      {\n        params: {\n          path: {\n            ref: projectId,\n          },\n        },\n        body: {\n          query,\n          read_only: options.readOnly,\n        },\n      }\n    );\n\n    assertSuccess(response, 'Failed to execute SQL query');\n\n    return response.data as unknown as T[];\n  }\n\n  async function getClosestRegion() {\n    return getClosestAwsRegion(getCountryCoordinates(await getCountryCode()))\n      .code;\n  }\n\n  const server = createMcpServer({\n    name: 'supabase',\n    version,\n    onInitialize(clientInfo) {\n      managementApiClient = createManagementApiClient(\n        managementApiUrl,\n        options.platform.accessToken,\n        {\n          'User-Agent': `supabase-mcp/${version} (${clientInfo.name}/${clientInfo.version})`,\n        }\n      );\n    },\n\n    // Note: tools are intentionally snake_case to align better with most MCP clients\n    tools: {\n      list_projects: tool({\n        description: 'Lists all Supabase projects for the user.',\n        parameters: z.object({}),\n        execute: async () => {\n          const response = await managementApiClient.GET('/v1/projects');\n\n          assertSuccess(response, 'Failed to fetch projects');\n\n          return response.data;\n        },\n      }),\n      get_project: tool({\n        description: 'Gets details for a Supabase project.',\n        parameters: z.object({\n          id: z.string().describe('The project ID'),\n        }),\n        execute: async ({ id }) => {\n          const response = await managementApiClient.GET('/v1/projects/{ref}', {\n            params: {\n              path: {\n                ref: id,\n              },\n            },\n          });\n          assertSuccess(response, 'Failed to fetch project');\n          return response.data;\n        },\n      }),\n      get_cost: tool({\n        description:\n          'Gets the cost of creating a new project or branch. Never assume organization as costs can be different for each.',\n        parameters: z.object({\n          type: z.enum(['project', 'branch']),\n          organization_id: z\n            .string()\n            .describe('The organization ID. Always ask the user.'),\n        }),\n        execute: async ({ type, organization_id }) => {\n          function generateResponse(cost: Cost) {\n            return `The new ${type} will cost $${cost.amount} ${cost.recurrence}. You must repeat this to the user and confirm their understanding.`;\n          }\n          switch (type) {\n            case 'project': {\n              const cost = await getNextProjectCost(\n                managementApiClient,\n                organization_id\n              );\n              return generateResponse(cost);\n            }\n            case 'branch': {\n              const cost = getBranchCost();\n              return generateResponse(cost);\n            }\n            default:\n              throw new Error(`Unknown cost type: ${type}`);\n          }\n        },\n      }),\n      confirm_cost: tool({\n        description:\n          'Ask the user to confirm their understanding of the cost of creating a new project or branch. Call `get_cost` first. Returns a unique ID for this confirmation which should be passed to `create_project` or `create_branch`.',\n        parameters: z.object({\n          type: z.enum(['project', 'branch']),\n          recurrence: z.enum(['hourly', 'monthly']),\n          amount: z.number(),\n        }),\n        execute: async (cost) => {\n          return await hashObject(cost);\n        },\n      }),\n      create_project: tool({\n        description:\n          'Creates a new Supabase project. Always ask the user which organization to create the project in. The project can take a few minutes to initialize - use `get_project` to check the status.',\n        parameters: z.object({\n          name: z.string().describe('The name of the project'),\n          region: z.optional(\n            z\n              .enum(AWS_REGION_CODES)\n              .describe(\n                'The region to create the project in. Defaults to the closest region.'\n              )\n          ),\n          organization_id: z.string(),\n          confirm_cost_id: z\n            .string({\n              required_error:\n                'User must confirm understanding of costs before creating a project.',\n            })\n            .describe('The cost confirmation ID. Call `confirm_cost` first.'),\n        }),\n        execute: async ({ name, region, organization_id, confirm_cost_id }) => {\n          const cost = await getNextProjectCost(\n            managementApiClient,\n            organization_id\n          );\n          const costHash = await hashObject(cost);\n          if (costHash !== confirm_cost_id) {\n            throw new Error(\n              'Cost confirmation ID does not match the expected cost of creating a project.'\n            );\n          }\n\n          const response = await managementApiClient.POST('/v1/projects', {\n            body: {\n              name,\n              region: region ?? (await getClosestRegion()),\n              organization_id,\n              db_pass: generatePassword({\n                length: 16,\n                numbers: true,\n                uppercase: true,\n                lowercase: true,\n              }),\n            },\n          });\n\n          assertSuccess(response, 'Failed to create project');\n\n          return response.data;\n        },\n      }),\n      pause_project: tool({\n        description: 'Pauses a Supabase project.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const response = await managementApiClient.POST(\n            '/v1/projects/{ref}/pause',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to pause project');\n        },\n      }),\n      restore_project: tool({\n        description: 'Restores a Supabase project.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const response = await managementApiClient.POST(\n            '/v1/projects/{ref}/restore',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n              body: {},\n            }\n          );\n\n          assertSuccess(response, 'Failed to restore project');\n        },\n      }),\n      list_organizations: tool({\n        description: 'Lists all organizations that the user is a member of.',\n        parameters: z.object({}),\n        execute: async () => {\n          const response = await managementApiClient.GET('/v1/organizations');\n\n          assertSuccess(response, 'Failed to fetch organizations');\n\n          return response.data;\n        },\n      }),\n      get_organization: tool({\n        description:\n          'Gets details for an organization. Includes subscription plan.',\n        parameters: z.object({\n          id: z.string().describe('The organization ID'),\n        }),\n        execute: async ({ id: organizationId }) => {\n          const response = await managementApiClient.GET(\n            '/v1/organizations/{slug}',\n            {\n              params: {\n                path: {\n                  slug: organizationId,\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to fetch organization');\n\n          return response.data;\n        },\n      }),\n      list_tables: tool({\n        description: 'Lists all tables in a schema.',\n        parameters: z.object({\n          project_id: z.string(),\n          schemas: z\n            .optional(z.array(z.string()))\n            .describe(\n              'Optional list of schemas to include. Defaults to all schemas.'\n            ),\n        }),\n        execute: async ({ project_id, schemas }) => {\n          const sql = listTablesSql(schemas);\n          const data = await executeSql<PostgresTable>(project_id, sql);\n          return data;\n        },\n      }),\n      list_extensions: tool({\n        description: 'Lists all extensions in the database.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const sql = listExtensionsSql();\n          const data = await executeSql<PostgresExtension>(project_id, sql);\n          return data;\n        },\n      }),\n      list_migrations: tool({\n        description: 'Lists all migrations in the database.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const response = await managementApiClient.GET(\n            '/v1/projects/{ref}/database/migrations',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to fetch migrations');\n\n          return response.data;\n        },\n      }),\n      apply_migration: tool({\n        description:\n          'Applies a migration to the database. Use this when executing DDL operations.',\n        parameters: z.object({\n          project_id: z.string(),\n          name: z.string().describe('The name of the migration in snake_case'),\n          query: z.string().describe('The SQL query to apply'),\n        }),\n        execute: async ({ project_id, name, query }) => {\n          if (options.readOnly) {\n            throw new Error('Cannot apply migration in read-only mode.');\n          }\n\n          const response = await managementApiClient.POST(\n            '/v1/projects/{ref}/database/migrations',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n              body: {\n                name,\n                query,\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to apply migration');\n\n          return response.data;\n        },\n      }),\n      execute_sql: tool({\n        description:\n          'Executes raw SQL in the Postgres database. Use `apply_migration` instead for DDL operations.',\n        parameters: z.object({\n          project_id: z.string(),\n          query: z.string().describe('The SQL query to execute'),\n        }),\n        execute: async ({ query, project_id }) => {\n          return await executeSql(project_id, query);\n        },\n      }),\n      get_logs: tool({\n        description:\n          'Gets logs for a Supabase project by service type. Use this to help debug problems with your app. This will only return logs within the last minute. If the logs you are looking for are older than 1 minute, re-run your test to reproduce them.',\n        parameters: z.object({\n          project_id: z.string(),\n          service: z\n            .enum([\n              'api',\n              'branch-action',\n              'postgres',\n              'edge-function',\n              'auth',\n              'storage',\n              'realtime',\n            ])\n            .describe('The service to fetch logs for'),\n        }),\n        execute: async ({ project_id, service }) => {\n          // Omitting start and end time defaults to the last minute.\n          // But since branch actions are async, we need to wait longer\n          // for jobs to be scheduled and run to completion.\n          const timestamp =\n            service === 'branch-action'\n              ? new Date(Date.now() - 5 * 60 * 1000)\n              : undefined;\n          const response = await managementApiClient.GET(\n            '/v1/projects/{ref}/analytics/endpoints/logs.all',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n                query: {\n                  iso_timestamp_start: timestamp?.toISOString(),\n                  sql: getLogQuery(service),\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to fetch logs');\n\n          return response.data;\n        },\n      }),\n\n      get_project_url: tool({\n        description: 'Gets the API URL for a project.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          return `https://${project_id}.supabase.co`;\n        },\n      }),\n      get_anon_key: tool({\n        description: 'Gets the anonymous API key for a project.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const response = await managementApiClient.GET(\n            '/v1/projects/{ref}/api-keys',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n                query: {\n                  reveal: false,\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to fetch API keys');\n\n          const anonKey = response.data?.find((key) => key.name === 'anon');\n\n          if (!anonKey) {\n            throw new Error('Anonymous key not found');\n          }\n\n          return anonKey.api_key;\n        },\n      }),\n      generate_typescript_types: tool({\n        description: 'Generates TypeScript types for a project.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const response = await managementApiClient.GET(\n            '/v1/projects/{ref}/types/typescript',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to fetch TypeScript types');\n\n          return response.data;\n        },\n      }),\n\n      // Experimental features\n      create_branch: tool({\n        description:\n          'Creates a development branch on a Supabase project. This will apply all migrations from the main project to a fresh branch database. Note that production data will not carry over. The branch will get its own project_id via the resulting project_ref. Use this ID to execute queries and migrations on the branch.',\n        parameters: z.object({\n          project_id: z.string(),\n          name: z\n            .string()\n            .default('develop')\n            .describe('Name of the branch to create'),\n          confirm_cost_id: z\n            .string({\n              required_error:\n                'User must confirm understanding of costs before creating a branch.',\n            })\n            .describe('The cost confirmation ID. Call `confirm_cost` first.'),\n        }),\n        execute: async ({ project_id, name, confirm_cost_id }) => {\n          const cost = getBranchCost();\n          const costHash = await hashObject(cost);\n          if (costHash !== confirm_cost_id) {\n            throw new Error(\n              'Cost confirmation ID does not match the expected cost of creating a branch.'\n            );\n          }\n\n          const createBranchResponse = await managementApiClient.POST(\n            '/v1/projects/{ref}/branches',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n              body: {\n                branch_name: name,\n              },\n            }\n          );\n\n          assertSuccess(createBranchResponse, 'Failed to create branch');\n\n          // Creating a default branch means we just enabled branching\n          // TODO: move this logic to API eventually.\n          if (createBranchResponse.data.is_default) {\n            await managementApiClient.PATCH('/v1/branches/{branch_id}', {\n              params: {\n                path: {\n                  branch_id: createBranchResponse.data.id,\n                },\n              },\n              body: {\n                branch_name: 'main',\n              },\n            });\n\n            const response = await managementApiClient.POST(\n              '/v1/projects/{ref}/branches',\n              {\n                params: {\n                  path: {\n                    ref: project_id,\n                  },\n                },\n                body: {\n                  branch_name: name,\n                },\n              }\n            );\n\n            assertSuccess(response, 'Failed to create branch');\n\n            return response.data;\n          }\n\n          return createBranchResponse.data;\n        },\n      }),\n      list_branches: tool({\n        description:\n          'Lists all development branches of a Supabase project. This will return branch details including status which you can use to check when operations like merge/rebase/reset complete.',\n        parameters: z.object({\n          project_id: z.string(),\n        }),\n        execute: async ({ project_id }) => {\n          const response = await managementApiClient.GET(\n            '/v1/projects/{ref}/branches',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n            }\n          );\n\n          // There are no branches if branching is disabled\n          if (response.response.status === 422) return [];\n          assertSuccess(response, 'Failed to list branches');\n\n          return response.data;\n        },\n      }),\n      delete_branch: tool({\n        description: 'Deletes a development branch.',\n        parameters: z.object({\n          branch_id: z.string(),\n        }),\n        execute: async ({ branch_id }) => {\n          const response = await managementApiClient.DELETE(\n            '/v1/branches/{branch_id}',\n            {\n              params: {\n                path: {\n                  branch_id,\n                },\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to delete branch');\n\n          return response.data;\n        },\n      }),\n      merge_branch: tool({\n        description:\n          'Merges migrations and edge functions from a development branch to production.',\n        parameters: z.object({\n          branch_id: z.string(),\n        }),\n        execute: async ({ branch_id }) => {\n          const response = await managementApiClient.POST(\n            '/v1/branches/{branch_id}/merge',\n            {\n              params: {\n                path: {\n                  branch_id,\n                },\n              },\n              body: {},\n            }\n          );\n\n          assertSuccess(response, 'Failed to merge branch');\n\n          return response.data;\n        },\n      }),\n      reset_branch: tool({\n        description:\n          'Resets migrations of a development branch. Any untracked data or schema changes will be lost.',\n        parameters: z.object({\n          branch_id: z.string(),\n          migration_version: z\n            .string()\n            .optional()\n            .describe(\n              'Reset your development branch to a specific migration version.'\n            ),\n        }),\n        execute: async ({ branch_id, migration_version }) => {\n          const response = await managementApiClient.POST(\n            '/v1/branches/{branch_id}/reset',\n            {\n              params: {\n                path: {\n                  branch_id,\n                },\n              },\n              body: {\n                migration_version,\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to reset branch');\n\n          return response.data;\n        },\n      }),\n      rebase_branch: tool({\n        description:\n          'Rebases a development branch on production. This will effectively run any newer migrations from production onto this branch to help handle migration drift.',\n        parameters: z.object({\n          branch_id: z.string(),\n        }),\n        execute: async ({ branch_id }) => {\n          const response = await managementApiClient.POST(\n            '/v1/branches/{branch_id}/push',\n            {\n              params: {\n                path: {\n                  branch_id,\n                },\n              },\n              body: {},\n            }\n          );\n\n          assertSuccess(response, 'Failed to rebase branch');\n\n          return response.data;\n        },\n      }),\n    },\n  });\n\n  return server;\n}\n","import { stripIndent } from 'common-tags';\n\nexport function getLogQuery(\n  service:\n    | 'api'\n    | 'branch-action'\n    | 'postgres'\n    | 'edge-function'\n    | 'auth'\n    | 'storage'\n    | 'realtime',\n  limit: number = 100\n) {\n  switch (service) {\n    case 'api':\n      return stripIndent`\n        select id, identifier, timestamp, event_message, request.method, request.path, response.status_code\n        from edge_logs\n        cross join unnest(metadata) as m\n        cross join unnest(m.request) as request\n        cross join unnest(m.response) as response\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'branch-action':\n      return stripIndent`\n        select workflow_run, workflow_run_logs.timestamp, id, event_message from workflow_run_logs\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'postgres':\n      return stripIndent`\n        select identifier, postgres_logs.timestamp, id, event_message, parsed.error_severity from postgres_logs\n        cross join unnest(metadata) as m\n        cross join unnest(m.parsed) as parsed\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'edge-function':\n      return stripIndent`\n        select id, function_edge_logs.timestamp, event_message, response.status_code, request.method, m.function_id, m.execution_time_ms, m.deployment_id, m.version from function_edge_logs\n        cross join unnest(metadata) as m\n        cross join unnest(m.response) as response\n        cross join unnest(m.request) as request\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'auth':\n      return stripIndent`\n        select id, auth_logs.timestamp, event_message, metadata.level, metadata.status, metadata.path, metadata.msg as msg, metadata.error from auth_logs\n        cross join unnest(metadata) as metadata\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'storage':\n      return stripIndent`\n        select id, storage_logs.timestamp, event_message from storage_logs\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'realtime':\n      return stripIndent`\n        select id, realtime_logs.timestamp, event_message from realtime_logs\n        order by timestamp desc\n        limit ${limit}\n      `;\n    default:\n      throw new Error(`unsupported log service type: ${service}`);\n  }\n}\n","-- Adapted from information_schema.columns\n\nSELECT\n  c.oid :: int8 AS table_id,\n  nc.nspname AS schema,\n  c.relname AS table,\n  (c.oid || '.' || a.attnum) AS id,\n  a.attnum AS ordinal_position,\n  a.attname AS name,\n  CASE\n    WHEN a.atthasdef THEN pg_get_expr(ad.adbin, ad.adrelid)\n    ELSE NULL\n  END AS default_value,\n  CASE\n    WHEN t.typtype = 'd' THEN CASE\n      WHEN bt.typelem <> 0 :: oid\n      AND bt.typlen = -1 THEN 'ARRAY'\n      WHEN nbt.nspname = 'pg_catalog' THEN format_type(t.typbasetype, NULL)\n      ELSE 'USER-DEFINED'\n    END\n    ELSE CASE\n      WHEN t.typelem <> 0 :: oid\n      AND t.typlen = -1 THEN 'ARRAY'\n      WHEN nt.nspname = 'pg_catalog' THEN format_type(a.atttypid, NULL)\n      ELSE 'USER-DEFINED'\n    END\n  END AS data_type,\n  COALESCE(bt.typname, t.typname) AS format,\n  a.attidentity IN ('a', 'd') AS is_identity,\n  CASE\n    a.attidentity\n    WHEN 'a' THEN 'ALWAYS'\n    WHEN 'd' THEN 'BY DEFAULT'\n    ELSE NULL\n  END AS identity_generation,\n  a.attgenerated IN ('s') AS is_generated,\n  NOT (\n    a.attnotnull\n    OR t.typtype = 'd' AND t.typnotnull\n  ) AS is_nullable,\n  (\n    c.relkind IN ('r', 'p')\n    OR c.relkind IN ('v', 'f') AND pg_column_is_updatable(c.oid, a.attnum, FALSE)\n  ) AS is_updatable,\n  uniques.table_id IS NOT NULL AS is_unique,\n  check_constraints.definition AS \"check\",\n  array_to_json(\n    array(\n      SELECT\n        enumlabel\n      FROM\n        pg_catalog.pg_enum enums\n      WHERE\n        enums.enumtypid = coalesce(bt.oid, t.oid)\n        OR enums.enumtypid = coalesce(bt.typelem, t.typelem)\n      ORDER BY\n        enums.enumsortorder\n    )\n  ) AS enums,\n  col_description(c.oid, a.attnum) AS comment\nFROM\n  pg_attribute a\n  LEFT JOIN pg_attrdef ad ON a.attrelid = ad.adrelid\n  AND a.attnum = ad.adnum\n  JOIN (\n    pg_class c\n    JOIN pg_namespace nc ON c.relnamespace = nc.oid\n  ) ON a.attrelid = c.oid\n  JOIN (\n    pg_type t\n    JOIN pg_namespace nt ON t.typnamespace = nt.oid\n  ) ON a.atttypid = t.oid\n  LEFT JOIN (\n    pg_type bt\n    JOIN pg_namespace nbt ON bt.typnamespace = nbt.oid\n  ) ON t.typtype = 'd'\n  AND t.typbasetype = bt.oid\n  LEFT JOIN (\n    SELECT DISTINCT ON (table_id, ordinal_position)\n      conrelid AS table_id,\n      conkey[1] AS ordinal_position\n    FROM pg_catalog.pg_constraint\n    WHERE contype = 'u' AND cardinality(conkey) = 1\n  ) AS uniques ON uniques.table_id = c.oid AND uniques.ordinal_position = a.attnum\n  LEFT JOIN (\n    -- We only select the first column check\n    SELECT DISTINCT ON (table_id, ordinal_position)\n      conrelid AS table_id,\n      conkey[1] AS ordinal_position,\n      substring(\n        pg_get_constraintdef(pg_constraint.oid, true),\n        8,\n        length(pg_get_constraintdef(pg_constraint.oid, true)) - 8\n      ) AS \"definition\"\n    FROM pg_constraint\n    WHERE contype = 'c' AND cardinality(conkey) = 1\n    ORDER BY table_id, ordinal_position, oid asc\n  ) AS check_constraints ON check_constraints.table_id = c.oid AND check_constraints.ordinal_position = a.attnum\nWHERE\n  NOT pg_is_other_temp_schema(nc.oid)\n  AND a.attnum > 0\n  AND NOT a.attisdropped\n  AND (c.relkind IN ('r', 'v', 'm', 'f', 'p'))\n  AND (\n    pg_has_role(c.relowner, 'USAGE')\n    OR has_column_privilege(\n      c.oid,\n      a.attnum,\n      'SELECT, INSERT, UPDATE, REFERENCES'\n    )\n  )\n","SELECT\n  e.name,\n  n.nspname AS schema,\n  e.default_version,\n  x.extversion AS installed_version,\n  e.comment\nFROM\n  pg_available_extensions() e(name, default_version, comment)\n  LEFT JOIN pg_extension x ON e.name = x.extname\n  LEFT JOIN pg_namespace n ON x.extnamespace = n.oid\n","SELECT\n  c.oid :: int8 AS id,\n  nc.nspname AS schema,\n  c.relname AS name,\n  c.relrowsecurity AS rls_enabled,\n  c.relforcerowsecurity AS rls_forced,\n  CASE\n    WHEN c.relreplident = 'd' THEN 'DEFAULT'\n    WHEN c.relreplident = 'i' THEN 'INDEX'\n    WHEN c.relreplident = 'f' THEN 'FULL'\n    ELSE 'NOTHING'\n  END AS replica_identity,\n  pg_total_relation_size(format('%I.%I', nc.nspname, c.relname)) :: int8 AS bytes,\n  pg_size_pretty(\n    pg_total_relation_size(format('%I.%I', nc.nspname, c.relname))\n  ) AS size,\n  pg_stat_get_live_tuples(c.oid) AS live_rows_estimate,\n  pg_stat_get_dead_tuples(c.oid) AS dead_rows_estimate,\n  obj_description(c.oid) AS comment,\n  coalesce(pk.primary_keys, '[]') as primary_keys,\n  coalesce(\n    jsonb_agg(relationships) filter (where relationships is not null),\n    '[]'\n  ) as relationships\nFROM\n  pg_namespace nc\n  JOIN pg_class c ON nc.oid = c.relnamespace\n  left join (\n    select\n      table_id,\n      jsonb_agg(_pk.*) as primary_keys\n    from (\n      select\n        n.nspname as schema,\n        c.relname as table_name,\n        a.attname as name,\n        c.oid :: int8 as table_id\n      from\n        pg_index i,\n        pg_class c,\n        pg_attribute a,\n        pg_namespace n\n      where\n        i.indrelid = c.oid\n        and c.relnamespace = n.oid\n        and a.attrelid = c.oid\n        and a.attnum = any (i.indkey)\n        and i.indisprimary\n    ) as _pk\n    group by table_id\n  ) as pk\n  on pk.table_id = c.oid\n  left join (\n    select\n      c.oid :: int8 as id,\n      c.conname as constraint_name,\n      nsa.nspname as source_schema,\n      csa.relname as source_table_name,\n      sa.attname as source_column_name,\n      nta.nspname as target_table_schema,\n      cta.relname as target_table_name,\n      ta.attname as target_column_name\n    from\n      pg_constraint c\n    join (\n      pg_attribute sa\n      join pg_class csa on sa.attrelid = csa.oid\n      join pg_namespace nsa on csa.relnamespace = nsa.oid\n    ) on sa.attrelid = c.conrelid and sa.attnum = any (c.conkey)\n    join (\n      pg_attribute ta\n      join pg_class cta on ta.attrelid = cta.oid\n      join pg_namespace nta on cta.relnamespace = nta.oid\n    ) on ta.attrelid = c.confrelid and ta.attnum = any (c.confkey)\n    where\n      c.contype = 'f'\n  ) as relationships\n  on (relationships.source_schema = nc.nspname and relationships.source_table_name = c.relname)\n  or (relationships.target_table_schema = nc.nspname and relationships.target_table_name = c.relname)\nWHERE\n  c.relkind IN ('r', 'p')\n  AND NOT pg_is_other_temp_schema(nc.oid)\n  AND (\n    pg_has_role(c.relowner, 'USAGE')\n    OR has_table_privilege(\n      c.oid,\n      'SELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER'\n    )\n    OR has_any_column_privilege(c.oid, 'SELECT, INSERT, UPDATE, REFERENCES')\n  )\ngroup by\n  c.oid,\n  c.relname,\n  c.relrowsecurity,\n  c.relforcerowsecurity,\n  c.relreplident,\n  nc.nspname,\n  pk.primary_keys\n","import { stripIndent } from 'common-tags';\nimport columnsSql from './columns.sql';\nimport extensionsSql from './extensions.sql';\nimport tablesSql from './tables.sql';\n\nexport const DEFAULT_SYSTEM_SCHEMAS = [\n  'information_schema',\n  'pg_catalog',\n  'pg_toast',\n];\n\n/**\n * Generates the SQL query to list tables in the database.\n */\nexport function listTablesSql(schemas: string[] = []) {\n  let sql = stripIndent`\n    with\n      tables as (${tablesSql}),\n      columns as (${columnsSql})\n    select\n      *,\n      ${coalesceRowsToArray('columns', 'columns.table_id = tables.id')}\n    from tables\n  `;\n\n  if (schemas.length > 0) {\n    sql += `  where schema in (${schemas.map((s) => `'${s}'`).join(',')})`;\n  } else {\n    sql += `  where schema not in (${DEFAULT_SYSTEM_SCHEMAS.map((s) => `'${s}'`).join(',')})`;\n  }\n\n  return sql;\n}\n\n/**\n * Generates the SQL query to list all extensions in the database.\n */\nexport function listExtensionsSql() {\n  return extensionsSql;\n}\n\n/**\n * Generates a SQL segment that coalesces rows into an array of JSON objects.\n */\nexport const coalesceRowsToArray = (source: string, filter: string) => {\n  return stripIndent`\n    COALESCE(\n      (\n        SELECT\n          array_agg(row_to_json(${source})) FILTER (WHERE ${filter})\n        FROM\n          ${source}\n      ),\n      '{}'\n    ) AS ${source}\n  `;\n};\n","import {\n  assertSuccess,\n  type ManagementApiClient,\n} from './management-api/index.js';\n\nexport const PROJECT_COST_MONTHLY = 10;\nexport const BRANCH_COST_HOURLY = 0.01344;\n\nexport type ProjectCost = {\n  type: 'project';\n  recurrence: 'monthly';\n  amount: number;\n};\n\nexport type BranchCost = {\n  type: 'branch';\n  recurrence: 'hourly';\n  amount: number;\n};\n\nexport type Cost = ProjectCost | BranchCost;\n\n/**\n * Gets the cost of the next project in an organization.\n */\nexport async function getNextProjectCost(\n  managementApiClient: ManagementApiClient,\n  orgId: string\n): Promise<Cost> {\n  const orgResponse = await managementApiClient.GET(\n    '/v1/organizations/{slug}',\n    {\n      params: {\n        path: {\n          slug: orgId,\n        },\n      },\n    }\n  );\n\n  assertSuccess(orgResponse, 'Failed to fetch organization');\n\n  const projectsResponse = await managementApiClient.GET('/v1/projects');\n\n  assertSuccess(projectsResponse, 'Failed to fetch projects');\n\n  const org = orgResponse.data;\n  const activeProjects = projectsResponse.data.filter(\n    (project) =>\n      project.organization_id === orgId &&\n      !['INACTIVE', 'GOING_DOWN', 'REMOVED'].includes(project.status)\n  );\n\n  let amount = 0;\n\n  if (org.plan !== 'free') {\n    // If the organization is on a paid plan, the first project is included\n    if (activeProjects.length > 0) {\n      amount = PROJECT_COST_MONTHLY;\n    }\n  }\n\n  return { type: 'project', recurrence: 'monthly', amount };\n}\n\n/**\n * Gets the cost for a database branch.\n */\nexport function getBranchCost(): Cost {\n  return { type: 'branch', recurrence: 'hourly', amount: BRANCH_COST_HOURLY };\n}\n","export type ValueOf<T> = T[keyof T];\n\n// UnionToIntersection<A | B> = A & B\nexport type UnionToIntersection<U> = (\n  U extends unknown ? (arg: U) => 0 : never\n) extends (arg: infer I) => 0\n  ? I\n  : never;\n\n// LastInUnion<A | B> = B\nexport type LastInUnion<U> =\n  UnionToIntersection<U extends unknown ? (x: U) => 0 : never> extends (\n    x: infer L\n  ) => 0\n    ? L\n    : never;\n\n// UnionToTuple<A, B> = [A, B]\nexport type UnionToTuple<T, Last = LastInUnion<T>> = [T] extends [never]\n  ? []\n  : [Last, ...UnionToTuple<Exclude<T, Last>>];\n\n/**\n * Parses a key-value string into an object.\n *\n * @returns An object representing the key-value pairs\n *\n * @example\n * const result = parseKeyValueList(\"key1=value1\\nkey2=value2\");\n * console.log(result); // { key1: \"value1\", key2: \"value2\" }\n */\nexport function parseKeyValueList(data: string): { [key: string]: string } {\n  return Object.fromEntries(\n    data\n      .split('\\n')\n      .map((item) => item.split(/=(.*)/)) // split only on the first '='\n      .filter(([key]) => key) // filter out empty keys\n      .map(([key, value]) => [key, value ?? '']) // ensure value is not undefined\n  );\n}\n\n/**\n * Creates a unique hash from a JavaScript object.\n * @param obj - The object to hash\n * @param length - Optional length to truncate the hash (default: full length)\n */\nexport async function hashObject(\n  obj: Record<string, any>,\n  length?: number\n): Promise<string> {\n  // Sort object keys to ensure consistent output regardless of original key order\n  const str = JSON.stringify(obj, (_, value) => {\n    if (value && typeof value === 'object' && !Array.isArray(value)) {\n      return Object.keys(value)\n        .sort()\n        .reduce<Record<string, any>>((result, key) => {\n          result[key] = value[key];\n          return result;\n        }, {});\n    }\n    return value;\n  });\n\n  const buffer = await crypto.subtle.digest(\n    'SHA-256',\n    new TextEncoder().encode(str)\n  );\n\n  // Convert to base64\n  const base64Hash = btoa(String.fromCharCode(...new Uint8Array(buffer)));\n  return base64Hash.slice(0, length);\n}\n"]}